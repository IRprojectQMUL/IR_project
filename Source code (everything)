IF THERE IS A SPACE BETWEEN LINES == RUN IN A SEPARATE CELL

!pip install kagglehub

!wget -q https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-oss-7.9.2-linux-x86_64.tar.gz
!wget -q https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-oss-7.9.2-linux-x86_64.tar.gz.sha512
!tar -xzf elasticsearch-oss-7.9.2-linux-x86_64.tar.gz
!sudo chown -R daemon:daemon elasticsearch-7.9.2/
!shasum -a 512 -c elasticsearch-oss-7.9.2-linux-x86_64.tar.gz.sha512

# https://stackoverflow.com/questions/68762774/elasticsearchunsupportedproducterror-the-client-noticed-that-the-server-is-no#answer-68918449
!pip install elasticsearch==7.9.1 -q

# check elasticsearch version in environment
!pip freeze | grep elasticsearch

!pip install --upgrade numpy==1.24.3

%%bash --bg
sudo -H -u daemon elasticsearch-7.9.2/bin/elasticsearch

%%bash
ps -ef | grep elasticsearch

import kagglehub
from elasticsearch import Elasticsearch
import time
import pandas as pd
import spacy
import string
from sklearn.feature_extraction.text import CountVectorizer

es = Elasticsearch("http://localhost:9200")
# Let's test whether we have succesfully started an ES instance and
# imported the python library
if es.ping():
  print('ES instance working')
else:
  print('ES instance not working')

# start es server
time.sleep(20) # give the server 20 seconds to start
!curl -X GET "http://localhost:9200"

path = kagglehub.dataset_download("snap/amazon-fine-food-reviews")
print("Path to dataset files:", path)

reviews = pd.read_csv('/root/.cache/kagglehub/datasets/snap/amazon-fine-food-reviews/versions/2/Reviews.csv')
reviews.head()

reviews = reviews.drop(['Id', 'UserId', 'ProfileName', 'HelpfulnessNumerator', 'HelpfulnessDenominator','Time'], axis=1)
reviews = reviews.dropna(subset=['Summary'])
reviews.head()



#load spaCy model for tokenisation and lemmatisation
nlp = spacy.load("en_core_web_sm")

#CountVectorizer for stopword removal
vectorizer = CountVectorizer(stop_words='english', binary=True)

#extract only the review text column - probably change this variable based on wat u guys did before 
reviews_text = [row[3] for row in reviews.values.tolist()]

#lowercase
reviews_text = [text.lower() for text in reviews_text]

#remove punctuation
reviews_text = [text.translate(str.maketrans('', '', string.punctuation)) for text in reviews_text]

#tokenisation
reviews_text = [[token.text for token in nlp(text)] for text in reviews_text]

#lemmatisation
reviews_text = [[token.lemma_ for token in nlp(" ".join(tokens))] for tokens in reviews_text]

#stopword
stopword_set = vectorizer.get_stop_words()
reviews_text = [[word for word in tokens if word not in stopword_set] for tokens in reviews_text]

print(reviews_text[:5])
